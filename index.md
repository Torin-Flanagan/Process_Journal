# Responsive Design and Technology Task 2 #
### Mobile Web App That Displays An Overview Of Key Components When Riding a Bike/Motorbike ###

## 1. Conceptualisation ##
### 1.1 Design Intent ###
Summary: A web app that cab be used by a user through a website address, then asking for permission to use the user's phone/device's geographic location, camera, and gyroscope for input. As a result, the web app will then be able to produce an output displaying the speed, which is calculated through obtaining the time travelled from point A - point B, along with presenting a display of the current lean/tilt angle. Lastly, it is key as prior knowledge that this web app can be used for anything bike/motorbike related due to the the app utilising the user's geographic location, camera, and gyroscope from their phone while riding a bike/motorbike. It should also be noted that a bike/motorcycle involved activity is not the only situation when this web app can be used, other examples could include using the web app while sailing, flying, snowboarding, etc.

### 1.2 Research ###
Through using research of other similiar project found on the web, it has helped to gain a deeper understanding of what myself, Sean, and Jay are aiming to achieve for the project, along with how we are going to do so. Research found during this phase will greatly affect what we aim to create paired with each phase during development. This will include how we develop the web interface, how this interface communicates with the user's phone, and what informational components of the user's phone we are aiming to extract data from? The influence of this research will be seen more apparent later within this process journal.

### 1.2.1 Related Project 1 ###

**A Smart Wheelchair**

![Alt text](./Images/Smart_Wheelchair.webp)

This project utilises a similiar concept as the concept we have devised ourselves. However, differences with the smart wheelchair incldue that the wheelchair iteslef comes with built-in sensors on the seat, collecting data every second in the background of the patient using the wheelchair. Data collected from this wheelchair then provides insight into the patient's seatin behaviours and the energy the patient requires in order to maintain correct posture. Another possible variation to this smart wheelchair could be to adapt fall detection so that the patient in the wheelchair knows when the wheelchair could possibly fall, giving time to call for assistance. These key features of the smart wheelchair then allow people to monitor the patient from a remote location, or more realistically when they are out of reach from that patient. A Possible idea from this project that could be interpreted into ours is being able to remotely access the data obtained, no matter where you are.

Reference: Deshpande, C. (2020, December 21). Top 10 Ultimate Internet of Things (IoT) Projects. Simplilearn.com. https://www.simplilearn.com/internet-of-things-iot-projects-article

### 1.2.2 Related Project 2 ###

**Road Sense**

![Alt text](./Images/Road%20Sense.gif)

The following project integrates a smartphone application designed to estimate road conditions using data from the accelerometer, gyroscope, and GPS. According to the research, machine learning techniques are applied to predict road quality based on this data. By leveraging the RoadSense app, the need for specialized vehicle sensors was eliminated, making the solution more scalable. The goal of the app is to provide users with real-time information on road conditions before they travel, potentially contributing to improved road infrastructure. The study highlights that combining data from the gyroscope and accelerometer proved to be the most effective approach, as these sensors can detect vehicle movements caused by potholes, rough surfaces, and other road irregularities. This insight is highly relevant to our project, as the accelerometer and gyroscope are effective in detecting sudden movements such as shakes, bumps, and tilts. These factors are essential characteristics of bike and motorbike usage, potentially making these sensors highly beneficial for advancing our project. 

Reference: Allouch, A., Koubaa, A., Abbes, T., & Ammar, A. (2017). RoadSense: Smartphone Application to Estimate Road Conditions Using Accelerometer and Gyroscope. IEEE Sensors Journal, 17(13), 4231–4238. https://doi.org/10.1109/jsen.2017.2702739

### 1.2.3 Related Project 3 ###

![Alt text](./Images/Portraits_Nebula.webp)

The third related project utilises the use of a camera in order to mimic the appearance of the user of the artwork, a similiar ideology of a mirror, but instead of a refelction the artwork uses flip-discs (small dime-size circles that can rotate 60 times per second usining electromagnets). Portraits Nebula is the name of the artwork and is summarised as an interactive kinetic artwork that uses customised flip-discs, when you engage with the artwork it will use a camera to record a breif clip of the interactions the user performs while being recorded. It then plays these cpatured interactions at a later time, eventually cycling through every portrait captured while the artwork/device has been initiated. In relation to our web app project, the artwork utilises the advantage of a camera in a similiar approach to our design which could possibly include snapshotting/recording interactions the user performs while using the web app.

Reference: Digital Kinetic Artwork - Portraits by BREAKFAST. (2024, July 16). BREAKFAST. https://breakfaststudio.com/works/portraits-nebula

### 1.2.4 Related Project 4 ###
‌
![Alt text](./Images/Asteroid_Suit.webp)

As seen above, the name of the suit is Ceres and it is a grey, jumpsuit like wearable technology that from afar looks like it just randomly vibrates as the user walks around with the jumpsuit on. However, in more detail the jumpsuit is equipped with small buzzers located near the user's shoulder blades and back, providing a buzz like sensation to the user's skin. The contributor as to why these buzzers are occuring on the users shoulder blades and back is due to the jumpsuit having microcontrollers connected to NASA's Near Earth Object API where these vibrations are indications of asteroids nearing Earth's orbit. It is quite clear that this related project is an example of how you can use geographic location of anything to then display in another form, with this example it is showing how the use of NASA's API obtains the geographic locations of asteroids near Earth's orbit, indicated by the jumpsuit lighting up and vibrating. With an example like this, it shows how open minded you can be in regards to using geographic location as a means to display any other form of responsive design. In relation to our project, an extended possibility using geographic location could be having the users phone record tracks and paths the user follows for furutre reference through similiar use with an API.

Reference: Plaugic, L. (2018, April 14). These three designers make wearables that measure the world around you. The Verge. https://www.theverge.com/2018/4/14/17233430/wearable-media-fashion-tech-nyc-ceres-jumpsuit-interactive

### 1.2.5 Related Project 5 ###

![Alt text](./Images/Human_Gyroscope.png)

Implementation of a gyroscope was created which could rotate 360 degrees in all dimensions, being controlled with a software-GUI paired with some type of joystick. Implementation of this project consists in the field of simulators such as a plane simulator, the design focuses on a gyroscopic view paired with software development, the prototype is more so seen as an idea for future investors who wish to apply this theology with a full scale, real-time used model, being much larger in price and scale. Regarding our project, this ideology can be used when considering the use of a gyroscope with the design, it will be viewed as treated in a similiar manner as seen in this example. The key difference however would be the implmentation of this gyroscopic use being obtained from the user's phone which then displays the user's tilt angle on the web app. In future development there could also be more extended use with a gyroscope such as utilising it for gesture-based navigation, motion controls, integrated augmented reality features responding to the user's movements, and etc.

Reference: Svensson, M. and Johannesson, J. (2013). The Human Gyroscope. [PDF] p.45. Available at: https://www.diva-portal.org/smash/get/diva2:647956/FULLTEXT01.pdf [Accessed 8 Sep. 2024].

‌